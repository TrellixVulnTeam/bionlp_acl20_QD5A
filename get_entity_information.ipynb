{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymetamap import MetaMap\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MetaMap.get_instance('/home/bsingh/public_mm/bin/metamap16') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ConceptMMI(index='0', mm='MMI', score='14.64', preferred_name='Myocardial Infarction', cui='C0027051', semtypes='[dsyn]', trigger='[\"-- Heart Attack\"-tx-1-\"Heart Attack\"-noun-0]', location='TX', pos_info='1/12', tree_codes='C14.280.647.500;C14.907.585.500'),\n",
       "  ConceptMMI(index='1', mm='MMI', score='17.80', preferred_name='Iodides', cui='C0021966', semtypes='[inch]', trigger='[\"I-\"-tx-1-\"I\"-noun-0]', location='TX', pos_info='1/1', tree_codes='D01.248.497.158.490;D01.475.410'),\n",
       "  ConceptMMI(index='1', mm='MMI', score='14.64', preferred_name='Myocardial Infarction', cui='C0027051', semtypes='[dsyn]', trigger='[\"-- Heart Attack\"-tx-1-\"heart attack\"-noun-0]', location='TX', pos_info='15/12', tree_codes='C14.280.647.500;C14.907.585.500'),\n",
       "  ConceptMMI(index='1', mm='MMI', score='5.18', preferred_name='Blood group antibody I', cui='C0221138', semtypes='[aapp,imft]', trigger='[\"I NOS\"-tx-1-\"I\"-noun-0]', location='TX', pos_info='1/1', tree_codes='')],\n",
       " None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the metamap instance is working.\n",
    "mm.extract_concepts(['Heart Attack', 'I am having a heart attack',], [0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working functions\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semantic_types_dict(list_, curr_list_concepts, sel_sem_types):\n",
    "    dict_con = {}\n",
    "    failed_con = 0\n",
    "    for ind in range(len(list_)):\n",
    "        dict_con[ind] = []\n",
    "    for each_con in tqdm(curr_list_concepts):\n",
    "        try:\n",
    "            pos_info = each_con.pos_info\n",
    "            pos_info = pos_info.replace('[','')\n",
    "            pos_info = pos_info.replace(']','')\n",
    "            if(';' in pos_info):\n",
    "                all_pos = pos_info.split(';')\n",
    "            else:\n",
    "                all_pos = pos_info.split(',')\n",
    "            all_pos_final = []\n",
    "            for each_pos in all_pos:\n",
    "                all_pos_final+=each_pos.split(',')\n",
    "            for each_pos in all_pos_final:\n",
    "                st = int(each_pos.split('/')[0])-1\n",
    "                end = st+int(each_pos.split('/')[1])\n",
    "                semtype_all = each_con.semtypes[1:-1].split(',')\n",
    "                semtype_all = [x for x in semtype_all if(x in sel_sem_types)]\n",
    "                # can be handled better\n",
    "                if(len(semtype_all)>0):\n",
    "                    semtype = semtype_all[0]\n",
    "                else:\n",
    "                    semtype = 'Ignore'\n",
    "                if(semtype in sel_sem_types):\n",
    "                    dict_con[int(each_con.index)].append([semtype, st, end, 1.0])\n",
    "        except:\n",
    "            failed_con+=1\n",
    "    print(\"Total_concepts\", curr_list_concepts.__len__())\n",
    "    print(\"Failed_concepts\", failed_con)\n",
    "    final_dict = {}\n",
    "    for ind in range(len(list_)):\n",
    "        final_dict[list_[ind]] = dict_con[ind]\n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_concepts(curr_mm, all_sents, batch_size=10):\n",
    "    all_concepts = []\n",
    "    for i in tqdm_notebook(range(0, all_sents.__len__(), batch_size)):\n",
    "        try:\n",
    "            curr_sents = all_sents[i:i+batch_size]\n",
    "            tmp = curr_mm.extract_concepts(curr_sents, [x for x in range(i, i+curr_sents.__len__())])\n",
    "            all_concepts.append(tmp)\n",
    "        except: \n",
    "            print(\"problem with the batch starting from\"+str(i))\n",
    "    return all_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_all_concepts(tmp_concepts):\n",
    "    final_concepts = []\n",
    "    for each_concept in tmp_concepts:\n",
    "        final_concepts+=each_concept[0]\n",
    "    return final_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('../data/emrqa_parawise_data.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we need the semantic types for the questions as well as paras from both splits\n",
    "all_data = data['strict_split']['train']+data['strict_split']['dev']+data['strict_split']['test']\n",
    "all_data = all_data+data['split']['train']+data['split']['dev']+data['split']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the evidence_sentence refers to the paragraphs extracted earlier.\n",
    "all_sents = [x['evidence_sentence'] for x in all_data]\n",
    "all_ques = [x['question'] for x in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sents = list(set(all_sents))\n",
    "all_ques = list(set(all_ques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_sem_types = open('../data/selected_semantic_types.txt','r').read()\n",
    "\n",
    "selected_sem_types = selected_sem_types.split('\\n')\n",
    "selected_sem_types = [x.split(':')[0].strip() for x in selected_sem_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acab',\n",
       " 'aggp',\n",
       " 'anab',\n",
       " 'anst',\n",
       " 'bpoc',\n",
       " 'cgab',\n",
       " 'clnd',\n",
       " 'diap',\n",
       " 'emod',\n",
       " 'evnt',\n",
       " 'fndg',\n",
       " 'inpo',\n",
       " 'lbpr',\n",
       " 'lbtr',\n",
       " 'phob',\n",
       " 'qlco',\n",
       " 'qnco',\n",
       " 'sbst',\n",
       " 'sosy',\n",
       " 'topp']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chosen semantic types\n",
    "selected_sem_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11aa980852ce417baada07a3769bb787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1185), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_emrqa_sents_con = get_all_concepts(all_sents=all_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7410691904b84bebb3ea9a93c714510d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9100), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_emrqa_ques_con = get_all_concepts(all_sents=all_ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_emrqa_sents_con = collate_all_concepts(all_emrqa_sents_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ed88d0b45e4a0b873861b94331eb9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=152378), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_concepts 152378\n",
      "Failed_concepts 5\n"
     ]
    }
   ],
   "source": [
    "dict_con_new_sent = get_semantic_types_dict(all_sents, final_emrqa_sents_con, selected_sem_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_emrqa_ques_con = collate_all_concepts(all_emrqa_ques_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f03a1e5a5b494eb5e348c6627673f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=759661), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_concepts 759661\n",
      "Failed_concepts 17\n"
     ]
    }
   ],
   "source": [
    "dict_con_new_ques = get_semantic_types_dict(all_ques, final_emrqa_ques_con, selected_sem_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumping the metamap annotations\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((dict_con_new_ques, dict_con_new_sent), \n",
    "            open('../data/metamap_annotations_emrqa_dict.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(selected_sem_types, open('../data/selected_ents.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the data with the semantic type infomrmation\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_dict = pickle.load(open('../data/metamap_annotations_emrqa_dict_all.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_concept_dict = concept_dict[0]\n",
    "sent_concept_dict = concept_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entity_information(list_, dict_ques, dict_sents):\n",
    "    for each_ in tqdm(list_):\n",
    "        each_['sent_ents'] = dict_sents[each_['evidence_sentence']]\n",
    "        each_['ques_ents'] = dict_ques[each_['question']]\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_entity_information(data['split']['train'], ques_concept_dict, sent_concept_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---'*10)\n",
    "print('Updated Datapoint Example')\n",
    "print('---'*10)\n",
    "print(data['split']['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_entity_information(data['split']['dev'], ques_concept_dict, sent_concept_dict)\n",
    "add_entity_information(data['split']['test'], ques_concept_dict, sent_concept_dict)\n",
    "##################### STRICT #####################\n",
    "add_entity_information(data['strict_split']['train'], ques_concept_dict, sent_concept_dict)\n",
    "add_entity_information(data['strict_split']['dev'], ques_concept_dict, sent_concept_dict)\n",
    "add_entity_information(data['strict_split']['test'], ques_concept_dict, sent_concept_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data, open('../data/emrqa_parawise_data_w_entities.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
